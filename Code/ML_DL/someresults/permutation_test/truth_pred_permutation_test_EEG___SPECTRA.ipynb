{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import datetime\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import os\n",
    "import time\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "basePath = \"/Users/macbookair/Desktop/università/computational intelligence/truth_predictor_project/models-data/data-from-eeglab/\"\n",
    "spectraBasePath = \"/Users/macbookair/Desktop/università/computational intelligence/truth_predictor_project/spectra_epoch/\"\n",
    "\n",
    "eegDataTarget = pd.DataFrame()\n",
    "eegDataNotTarget = pd.DataFrame()\n",
    "\n",
    "spectraDataTarget = pd.DataFrame()\n",
    "spectraDataNotTarget = pd.DataFrame()\n",
    "\n",
    "allSubjectList = os.listdir(basePath)\n",
    "\n",
    "for subjectName in allSubjectList:\n",
    "    if os.path.isdir(basePath + subjectName):\n",
    "        singleSubjectFiles = os.listdir(basePath + subjectName)\n",
    "        for targetFileName in  singleSubjectFiles:\n",
    "            if \"epIs\" in targetFileName and \"EEG.csv\" in targetFileName:\n",
    "                #put file name in target array\n",
    "                targetFile = pd.read_csv(basePath + subjectName + \"/\" + targetFileName,sep=\"\\t\")\n",
    "                eegDataTarget = pd.concat([eegDataTarget,targetFile])\n",
    "                spectraFileNameTarget = spectraBasePath + targetFileName.replace(\"EEG.csv\",\"SPECTRA.csv\")\n",
    "                if os.path.exists(spectraFileNameTarget):\n",
    "                    spectraTargetFile = pd.read_csv(spectraFileNameTarget, header=None)\n",
    "                else:\n",
    "                    spectraTargetFile = pd.read_csv(spectraBasePath + targetFileName.replace(\"EEG.csv\",\"EEG-SPECTRA.csv\"), header=None)\n",
    "                spectraDataTarget = pd.concat([spectraDataTarget,spectraTargetFile])\n",
    "            elif \"epNot\" in targetFileName and \"EEG.csv\" in targetFileName:\n",
    "                #put file name in not_target array\n",
    "                notTargetFile = pd.read_csv(basePath + subjectName + \"/\" + targetFileName,sep=\"\\t\")\n",
    "                eegDataNotTarget = pd.concat([eegDataNotTarget,notTargetFile])\n",
    "                spectraFileNameNotTarget = spectraBasePath + targetFileName.replace(\"EEG.csv\",\"SPECTRA.csv\")\n",
    "                if os.path.exists(spectraFileNameNotTarget):\n",
    "                    spectraNotTargetFile = pd.read_csv(spectraFileNameNotTarget, header=None)\n",
    "                else:\n",
    "                    spectraNotTargetFile = pd.read_csv(spectraBasePath + targetFileName.replace(\"EEG.csv\",\"EEG-SPECTRA.csv\"), header=None)\n",
    "                spectraDataNotTarget = pd.concat([spectraDataTarget,spectraNotTargetFile])\n",
    "                \n",
    "eegDataTarget.rename(index=str, columns={\" \": \"Time\"},inplace=True)\n",
    "del eegDataTarget[\"Unnamed: 5\"]\n",
    "\n",
    "eegDataNotTarget.rename(index=str, columns={\" \": \"Time\"},inplace=True)\n",
    "del eegDataNotTarget[\"Unnamed: 5\"]\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "windowStart = 0\n",
    "windowEnd = 3000\n",
    "numberOfSeconds = (windowEnd - windowStart)/ 1000\n",
    "numberOfSamplesPerRound = int(numberOfSeconds * 256)\n",
    "\n",
    "eegDataTargetReduced = eegDataTarget[(eegDataTarget[\"Time\"] >= windowStart) & (eegDataTarget[\"Time\"] < windowEnd)]\n",
    "eegDataNotTargetReduced = eegDataNotTarget[(eegDataNotTarget[\"Time\"] >= windowStart) & (eegDataNotTarget[\"Time\"] < windowEnd)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndel eegDataNotTargetReduced[\"Time\"]\\ndel eegDataTargetReduced[\"Time\"]\\n'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "del eegDataNotTargetReduced[\"Time\"]\n",
    "del eegDataTargetReduced[\"Time\"]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "eegDataTargetReducedNumpy = np.array(eegDataTargetReduced.values)\n",
    "numberOfTargetValues = int(eegDataTargetReduced.shape[0]/numberOfSamplesPerRound)\n",
    "trainingTargetSet = np.array(np.array_split(eegDataTargetReducedNumpy, eegDataTargetReduced.shape[0]/numberOfSamplesPerRound))\n",
    "\n",
    "eegDataNotTargetReducedNumpy = np.array(eegDataNotTargetReduced.values)\n",
    "trainingNotTargetSet = np.array(np.array_split(eegDataNotTargetReducedNumpy, eegDataNotTargetReduced.shape[0]/numberOfSamplesPerRound))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectraDataTargetReducedNumpy = np.array(spectraDataTarget.values)\n",
    "trainingSpectraTargetSet = np.array(np.array_split(spectraDataTargetReducedNumpy, spectraDataTarget.shape[0]/4))\n",
    "\n",
    "spectraDataNotTargetReducedNumpy = np.array(spectraDataNotTarget.values)\n",
    "trainingSpectraNotTargetSet = np.array(np.array_split(spectraDataNotTargetReducedNumpy, spectraDataNotTarget.shape[0]/4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3220, 129)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectraDataTargetReducedNumpy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(804, 4356)\n",
      "(804, 4356)\n"
     ]
    }
   ],
   "source": [
    "trainingTargetSetReshaped = []\n",
    "trainingNotTargetSetReshaped = []\n",
    "for i in range(numberOfTargetValues - 1):\n",
    "    trainingTargetSetReshaped.append(np.hstack((trainingTargetSet[i].flatten(),trainingSpectraTargetSet[i].flatten())))\n",
    "    \n",
    "for i in range(numberOfTargetValues - 1):\n",
    "    trainingNotTargetSetReshaped.append(np.hstack((trainingNotTargetSet[i].flatten(),trainingSpectraNotTargetSet[i].flatten())))\n",
    "    \n",
    "trainingTargetSetReshaped = np.array(trainingTargetSetReshaped)\n",
    "trainingNotTargetSetReshaped = np.array(trainingNotTargetSetReshaped)\n",
    "\n",
    "print(trainingTargetSetReshaped.shape)\n",
    "print(trainingNotTargetSetReshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(804, 4356)\n",
      "(804, 4356)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#UNCOMMENT FOR TAKING AVERAGES\n",
    "trainingTargetSetReshapedAndAveraged = np.zeros((trainingTargetSetReshaped.shape[0],trainingTargetSetReshaped.shape[1]))\n",
    "trainingNotTargetSetReshapedAndAveraged = np.zeros((trainingTargetSetReshaped.shape[0],trainingTargetSetReshaped.shape[1]))\n",
    "\n",
    "numberOfElectrodesLinesToBeAveragedPerSide = 15\n",
    "numberOfElectrodesLinesToBeAveraged = (numberOfElectrodesLinesToBeAveragedPerSide * 2) + 1\n",
    "numberOfAttributesConsidered = 5\n",
    "totalNumberOfAttributesToJump = numberOfElectrodesLinesToBeAveragedPerSide * numberOfAttributesConsidered\n",
    "\n",
    "for i in range(trainingTargetSetReshaped.shape[0]):\n",
    "    for j in range(trainingTargetSetReshaped.shape[1]):\n",
    "        if j < 3072 and j >= totalNumberOfAttributesToJump and j < trainingTargetSetReshaped.shape[1] - totalNumberOfAttributesToJump:\n",
    "            z = 0\n",
    "            while z <= numberOfElectrodesLinesToBeAveragedPerSide:\n",
    "                if z != 0:\n",
    "                    trainingTargetSetReshapedAndAveraged[i][j] += trainingTargetSetReshaped[i][j - (numberOfAttributesConsidered * z)]\n",
    "                \n",
    "                trainingTargetSetReshapedAndAveraged[i][j] += trainingTargetSetReshaped[i][j + (numberOfAttributesConsidered * z)]\n",
    "                z = z + 1\n",
    "            trainingTargetSetReshapedAndAveraged[i][j] = trainingTargetSetReshapedAndAveraged[i][j] / numberOfElectrodesLinesToBeAveraged\n",
    "        else:\n",
    "            trainingTargetSetReshapedAndAveraged[i][j] = trainingTargetSetReshaped[i][j]\n",
    "    \n",
    "    \n",
    "for i in range(trainingTargetSetReshaped.shape[0]):\n",
    "    for j in range(trainingTargetSetReshaped.shape[1]):\n",
    "        if j < 3072 and j >= totalNumberOfAttributesToJump and j < trainingNotTargetSetReshaped.shape[1] - totalNumberOfAttributesToJump:\n",
    "            z = 0\n",
    "            while z <= numberOfElectrodesLinesToBeAveragedPerSide:\n",
    "                if z != 0:\n",
    "                    trainingNotTargetSetReshapedAndAveraged[i][j] += trainingNotTargetSetReshaped[i][j - (numberOfAttributesConsidered * z)]\n",
    "                \n",
    "                trainingNotTargetSetReshapedAndAveraged[i][j] += trainingNotTargetSetReshaped[i][j + (numberOfAttributesConsidered * z)]\n",
    "                z = z + 1\n",
    "            trainingNotTargetSetReshapedAndAveraged[i][j] = trainingNotTargetSetReshapedAndAveraged[i][j] / numberOfElectrodesLinesToBeAveraged\n",
    "        else:\n",
    "            trainingNotTargetSetReshapedAndAveraged[i][j] = trainingNotTargetSetReshaped[i][j]\n",
    "\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(804, 4356)\n",
      "(804, 4356)\n"
     ]
    }
   ],
   "source": [
    "print(trainingTargetSetReshapedAndAveraged.shape)\n",
    "print(trainingNotTargetSetReshapedAndAveraged.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingTargetSetReshaped = trainingTargetSetReshapedAndAveraged\n",
    "trainingNotTargetSetReshaped = trainingNotTargetSetReshapedAndAveraged\n",
    "\n",
    "validationTargetSetReshaped = trainingTargetSetReshaped[700:-1]\n",
    "validationNotTargetSetReshaped = trainingNotTargetSetReshaped[700:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfTargetValues = 700\n",
    "numberOfNotTarget = numberOfTargetValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingTargetSetReshapedAndReduced = trainingTargetSetReshaped[0:numberOfTargetValues]\n",
    "trainingNotTargetSetReshapedAndReduced = trainingNotTargetSetReshaped[0:numberOfTargetValues]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HERE EQUIPROBABILITY\n",
    "numberOfNotTarget = numberOfTargetValues\n",
    "trainingNotTargetSet = trainingNotTargetSet[0:numberOfNotTarget]\n",
    "\n",
    "trainingSpectraNotTargetSet = trainingSpectraNotTargetSet[0:numberOfNotTarget]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 4356)\n",
      "(1400,)\n"
     ]
    }
   ],
   "source": [
    "trainingSet = np.concatenate((trainingTargetSetReshapedAndReduced,trainingNotTargetSetReshapedAndReduced))\n",
    "\n",
    "trainingSetLabelsOnes = np.ones((numberOfTargetValues,), dtype=int)\n",
    "trainingSetLabelsZeros = np.zeros((numberOfNotTarget,), dtype=int)\n",
    "trainingLabels = np.concatenate((trainingSetLabelsOnes,trainingSetLabelsZeros))\n",
    "print(trainingSet.shape)\n",
    "print(trainingLabels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf300Score = 0\n",
    "rf400Score = 0\n",
    "rf450Score = 0\n",
    "\n",
    "gradBoostScore = 0\n",
    "\n",
    "rf300oobScore = 0\n",
    "rf400oobScore = 0\n",
    "rf450oobScore = 0\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(trainingSet)\n",
    "trainingSet = scaler.transform(trainingSet)\n",
    "\n",
    "applyPCA = False\n",
    " \n",
    "if applyPCA:\n",
    "    #here fitting PCA\n",
    "    pca = PCA(.999).fit(trainingSet)\n",
    "    #transforming in lower dimensional space\n",
    "    trainingSet = pca.transform(trainingSet)\n",
    "    \n",
    "start_time = time.time()\n",
    "\n",
    "numberOfPermutations = 250\n",
    "\n",
    "np.random.shuffle(trainingLabels)\n",
    "\n",
    "scoreList = list()\n",
    "\n",
    "for i in range(numberOfPermutations):\n",
    "    \n",
    "    train, test, labels, testLabels = train_test_split(trainingSet,trainingLabels,test_size=0.2,random_state=42)\n",
    "    np.random.shuffle(trainingLabels)\n",
    "    \n",
    "    rf450 = RandomForestClassifier(n_estimators=450,n_jobs=-1)\n",
    "    rf450.fit(train, labels)\n",
    "    score = rf450.score(test,testLabels)\n",
    "    rf450Score += score\n",
    "    scoreList.append(score)\n",
    "    \n",
    "    '''\n",
    "    rf300 = RandomForestClassifier(n_estimators=300,n_jobs=-1)\n",
    "    rf300.fit(train, labels)\n",
    "    rf300Score += rf300.score(test,testLabels)\n",
    "    \n",
    "    rf400 = RandomForestClassifier(n_estimators=400,n_jobs=-1)\n",
    "    rf400.fit(train, labels)\n",
    "    rf400Score += rf400.score(test,testLabels)\n",
    "    \n",
    "    gradBoost = GradientBoostingClassifier()\n",
    "    gradBoost.fit(train,labels)\n",
    "    gradBoostScore += gradBoost.score(test,testLabels)\n",
    "    '''\n",
    "\n",
    "'''\n",
    "print(\"grad boost score:\",end=\"\")\n",
    "print(gradBoostScore/numberOfFolds)\n",
    "print(\"grad boost conf:\")\n",
    "print(confusion_matrix(testLabels, gradBoost.predict(test)))\n",
    "print(\"\")\n",
    "\n",
    "print(\"RF-300 oob_score:\",end=\"\")\n",
    "print(rf300oobScore)\n",
    "print(\"\")\n",
    "\n",
    "print(\"RF-400 oob_score:\",end=\"\")\n",
    "print(rf400oobScore)\n",
    "print(\"\")\n",
    "'''\n",
    "\n",
    "print(\"RF-450 average score:\",end=\"\")\n",
    "print(rf450Score / numberOfPermutations)\n",
    "print(\"\")\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Execution time: \")\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(scoreList).to_csv(\"/Users/macbookair/Desktop/università/computational intelligence/truth_predictor_project/permutation_scores/permutation_scores_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF-450:0.5\n",
      "RF conf:\n",
      "[[41 62]\n",
      " [41 62]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "validationSet = np.concatenate((validationTargetSetReshaped,validationNotTargetSetReshaped))\n",
    "\n",
    "validationSet = scaler.transform(validationSet)\n",
    "\n",
    "if applyPCA:\n",
    "    validationSet = pca.transform(validationSet)\n",
    "\n",
    "labelsNumber = int(validationSet.shape[0]/2)\n",
    "validationSetLabelsOnes = np.ones((labelsNumber,), dtype=int)\n",
    "validationSetLabelsZeros = np.zeros((labelsNumber,), dtype=int)\n",
    "validationLabels = np.concatenate((validationSetLabelsOnes,validationSetLabelsZeros))\n",
    "'''\n",
    "print(\"RF-400 oob score:\",end=\"\")\n",
    "print(rf400oob.score(validationSet,validationLabels))\n",
    "print(\"RF conf:\")\n",
    "print(confusion_matrix(validationLabels, rf400oob.predict(validationSet)))\n",
    "print(\"\")\n",
    "\n",
    "'''\n",
    "print(\"RF-450:\",end=\"\")\n",
    "print(rf450.score(validationSet,validationLabels))\n",
    "print(\"RF conf:\")\n",
    "print(confusion_matrix(validationLabels, rf450.predict(validationSet)))\n",
    "print(\"\")\n",
    "'''\n",
    "print(\"grad boost score:\",end=\"\")\n",
    "print(gradBoost.score(validationSet,validationLabels))\n",
    "print(\"grad boost conf:\")\n",
    "print(confusion_matrix(validationLabels, gradBoost.predict(validationSet)))\n",
    "print(\"\")\n",
    "'''\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
